{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"OpsML Overview","text":"Tooling for machine learning workflows Supported Model Types <p>Source Code: Code</p>"},{"location":"#what-is-it","title":"What is it?","text":"<p><code>OpsML</code> is a tooling library that simplifies the machine learning project lifecycle.</p>"},{"location":"#features","title":"Features","text":"<ul> <li> <p><code>Shareable</code>: Share cards and workflows across teams</p> </li> <li> <p><code>Simple Design</code>: Standardized design that can easily be incorporated into existing workflows.</p> </li> <li> <p><code>Cards</code>: Track, version, and store a variety of ML artifacts via cards (data, models, runs, pipelines) and a SQL-based card registry system. Think \"trading cards for machine learning\".</p> </li> <li> <p><code>Automation</code>: Automated processes including Onnx model conversion, api generation from Onnx model, data schema inference, code conversion and packaging for production.</p> </li> <li> <p><code>Pipelines</code>: Coming soon. Auto-pipeline creation</p> </li> </ul>"},{"location":"#why","title":"Why?","text":"<p>The main goal of <code>Opsml</code> is to provide an intuitive interface for DSs to create standardized, resuable and auditable machine learning workflows.</p>"},{"location":"#two-sides-of-the-same-coin-dev-as-prod","title":"Two sides of the same coin (dev as prod)","text":"<p>Taking a data science project from ideation  to deployment  often involves a <code>dev</code> side and a <code>deployment</code> side. </p>"},{"location":"#dev-themes","title":"Dev Themes:","text":"<ul> <li>Experimentation and iteration in order to generate many potential solutions</li> <li>Feature/Data engineering</li> <li>Algorithm development</li> <li>Felxible work environment (often Jupyter Notebooks)</li> <li>Many other things</li> </ul>"},{"location":"#deployment-themes","title":"Deployment Themes:","text":"<ul> <li>Compute infrastructure for hosting</li> <li>Conversion of data science code to production code (including creating dags/pipelines)</li> <li>CI/CD</li> <li>Versioning</li> <li>Monitoring</li> <li>Security</li> </ul>"},{"location":"#resulting-pain-points","title":"Resulting Pain Points","text":"<ul> <li> <p> Overhead in packaging data science code into production code. This results in duplicating data science code just to run in another environment (necessary, but can this be simplified?). </p> </li> <li> <p> Time lag in deployment due to different teams having different priorities (especially true if developers/ML engineers are needed to help data scientists deploy their code)</p> </li> <li> <p> Inflexible prod code that is not easily updatable</p> </li> <li> <p> Often no linking of metadata across the entire workflow (data, runs/experiments, models, pipelines)</p> </li> </ul> <p>What <code>Opsml</code> aims to do is provide an interface into both sides and simplify the entire workflow experience by removing non-value added time from <code>dev</code> and <code>deployment</code> processes and help teams go from ideation to deployment quicker  with the added benefits of reproducibility and auditability.</p>"},{"location":"#installation","title":"Installation","text":"<p>Before installing, you'll need to set up your Artifactory credentials.</p> <p>Request credentials for Artifactory in Slack <code>#ask-info-sec</code></p> <p>Once you have your credentials, set the following variables. <pre><code>export POETRY_HTTP_BASIC_SHIPT_RESOLVE_USERNAME=your_username\nexport POETRY_HTTP_BASIC_SHIPT_RESOLVE_PASSWORD=your_password\n</code></pre></p> <p>If using poetry, you must also add the following in your <code>pyproject.toml</code> <pre><code>[[tool.poetry.source]]\nname = \"shipt-resolve\"\nurl = \"https://artifactory.shipt.com/artifactory/api/pypi/pypi-virtual/simple\"\ndefault = true\n</code></pre></p> <p>Next, add opsml to your environment <pre><code>poetry add opsml\n</code></pre></p>"},{"location":"#optional-dependencies","title":"Optional Dependencies","text":"<p><code>Opsml</code> is designed to work with a variety of 3rd-party integrations depending on your use-case.</p> <p>Types of extras that can be installed:</p> <ul> <li> <p>Postgres: Installs postgres pyscopg2 dependency to be used with <code>Opsml</code> <pre><code>poetry add \"opsml[postgres]\"\n</code></pre></p> </li> <li> <p>Server: Installs necessary packages for setting up an <code>Fastapi</code>/<code>Mlflow</code> based <code>Opsml</code> server   <pre><code>poetry add \"opsml[server]\"\n</code></pre></p> </li> <li> <p>Mlflow: Installs Mlflow for client-side interaction with an <code>Opsml</code> server   <pre><code>poetry add \"opsml[mlflow]\"\n</code></pre></p> </li> <li> <p>GCP-mysql: Installs mysql and cloud-sql gcp dependencies to be used with <code>Opsml</code> <pre><code>poetry add \"opsml[gcp_mysql]\"\n</code></pre></p> </li> <li> <p>GCP-postgres: Installs postgres and cloud-sql gcp dependencies to be used with <code>Opsml</code> <pre><code>poetry add \"opsml[gcp_postgres]\"\n</code></pre></p> </li> </ul>"},{"location":"#environment-variables","title":"Environment Variables","text":"<p><code>Opsml</code> requires 1 or 2 environment variables depending on if you are using it as an all-in-one interface (no proxy) or you are using it as an interface to interact with an <code>Opsml</code> server (details on how to set up an <code>Opsml</code> server are below (TODO))</p> <ul> <li> <p>OPSML_TRACKING_URI: This is the sql tracking uri to your card registry database. If interacting with an <code>Opsml</code> server, this will be the http address of the server. If this variable is not set, it will default to a local <code>SQLite</code> connection.</p> </li> <li> <p>OPSML_STORAGE_URI: This is the storage uri to use for storing ml artifacts (models, data, figures, etc.). <code>Opsml</code> currently supports local file systems and google cloud storage. If running <code>Opsml</code> as an all-in-one interface, this variable is required and will default to a local folder if not specified. If interacting with an <code>Opsml</code> server, this variable does not need to be set.</p> </li> </ul>"},{"location":"#example","title":"Example","text":"<p>The primary interface for <code>Opsml</code> is an <code>ArtifactCard</code> (see here for detailed information). All Cards within <code>Opsml</code> follow the same design with a few specific required arguments for each card type. The following example shows how to create a DataCard and a ModelCard.</p> <p><pre><code># Data and Model\nfrom sklearn.datasets import load_linnerud\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\n\n# Opsml\nfrom opsml.registry import CardInfo, DataCard, CardRegistry, ModelCard\n\n# set up registries\ndata_registry = CardRegistry(registry_name=\"data\")\nmodel_registry = CardRegistry(registry_name=\"model\")\n\n# card info (optional, but is used to simplify required args a bit)\ncard_info = CardInfo(name=\"linnerrud\", team=\"opsml\", user_email=\"user@email.com\")\n\n# get X, y\ndata, target = load_linnerud(return_X_y=True, as_frame=True)\ndata[\"Pulse\"] = target.Pulse\n\n# Split indices\nindices = np.arange(data.shape[0])\n\n# usual train-test split\ntrain_idx, test_idx = train_test_split(indices, test_size=0.2, train_size=None)\n\ndatacard = DataCard(\n    info=card_info,\n    data=data,\n    dependent_vars=[\"Pulse\"],\n    # define splits\n    data_splits=[\n        {\"label\": \"train\", \"indices\": train_idx},\n        {\"label\": \"test\", \"indices\": test_idx},\n    ],\n)\n\n# register card\ndata_registry.register_card(datacard)\n\n# split data\ndata_splits = datacard.split_data()\nX_train = data_splits.train\ny_train = data_splits.train.pop(datacard.dependent_vars[0])\n\n# fit model\nlinreg = LinearRegression()\nlinreg = linreg.fit(X=X_train, y=y_train)\n\n# Create ModelCard\nmodelcard = ModelCard(\n    info=card_info,\n    trained_model=linreg,\n    sample_input_data=X_train,\n    datacard_uid=datacard.uid,\n)\n\nmodel_registry.register_card(card=modelcard)\n\n# &gt;{\"level\": \"INFO\", \"message\": \"OPSML_DATA_REGISTRY: linnerrud, version:1.0.0 registered\", \"timestamp\": \"2023-04-27T19:12:30\", \"app_env\": \"development\"}\n# &gt;{\"level\": \"INFO\", \"message\": \"Validating converted onnx model\", \"timestamp\": \"2023-04-27T19:12:30\", \"app_env\": \"development\"}\n# &gt;{\"level\": \"INFO\", \"message\": \"Onnx model validated\", \"timestamp\": \"2023-04-27T19:12:30\", \"app_env\": \"development\"}\n# &gt;{\"level\": \"INFO\", \"message\": \"OPSML_MODEL_REGISTRY: linnerrud, version:1.0.0 registered\", \"timestamp\": \"2023-04-27T19:12:30\", \"app_env\": \"development\"}\n\n\nprint(data_registry.list_cards(info=card_info, as_dataframe=False))\nprint(model_registry.list_cards(info=card_info, as_dataframe=False))\n</code></pre> (Code will run as-is)</p> <p>Outputs:</p> <pre><code># data registry output\n[\n{\n\"uid\": \"3fa6f762c5b74d4289b1e52bfd66f158\",\n\"app_env\": \"development\",\n\"team\": \"opsml\",\n\"user_email\": \"user@email.com\",\n\"datacard_uid\": \"873978bf4c3a49be819b9813f8d02ae8\",\n\"onnx_model_uri\": \"/***/***/opsml_artifacts/OPSML_MODEL_REGISTRY/opsml/linnerrud/v-1.0.0/api-def.json\",\n\"sample_data_type\": \"DataFrame\",\n\"runcard_uid\": None,\n\"timestamp\": 1682622948628464,\n\"date\": \"2023-04-27\",\n\"name\": \"linnerrud\",\n\"version\": \"1.0.0\",\n\"modelcard_uri\": \"/***/***/opsml_artifacts/OPSML_MODEL_REGISTRY/opsml/linnerrud/v-1.0.0/modelcard.joblib\",\n\"trained_model_uri\": \"/***/***/opsml_artifacts/OPSML_MODEL_REGISTRY/opsml/linnerrud/v-1.0.0/trained-model.joblib\",\n\"sample_data_uri\": \"/***/***/opsml_artifacts/OPSML_MODEL_REGISTRY/opsml/linnerrud/v-1.0.0/sample-model-data.parquet\",\n\"model_type\": \"sklearn_estimator\",\n\"pipelinecard_uid\": None,\n}\n]\n\n# model registry output\n[\n{\n\"uid\": \"3fa6f762c5b74d4289b1e52bfd66f158\",\n\"app_env\": \"development\",\n\"team\": \"opsml\",\n\"user_email\": \"user@email.com\",\n\"datacard_uid\": \"873978bf4c3a49be819b9813f8d02ae8\",\n\"onnx_model_uri\": \"/***/***/opsml_artifacts/OPSML_MODEL_REGISTRY/opsml/linnerrud/v-1.0.0/api-def.json\",\n\"sample_data_type\": \"DataFrame\",\n\"runcard_uid\": None,\n\"timestamp\": 1682622948628464,\n\"date\": \"2023-04-27\",\n\"name\": \"linnerrud\",\n\"version\": \"1.0.0\",\n\"modelcard_uri\": \"/***/***/opsml_artifacts/OPSML_MODEL_REGISTRY/opsml/linnerrud/v-1.0.0/modelcard.joblib\",\n\"trained_model_uri\": \"/***/***/opsml_artifacts/OPSML_MODEL_REGISTRY/opsml/linnerrud/v-1.0.0/trained-model.joblib\",\n\"sample_data_uri\": \"/***/***/opsml_artifacts/OPSML_MODEL_REGISTRY/opsml/linnerrud/v-1.0.0/sample-model-data.parquet\",\n\"model_type\": \"sklearn_estimator\",\n\"pipelinecard_uid\": None,\n}\n]\n</code></pre>"},{"location":"cards/datacard/","title":"DataCard","text":"<p>DataCards are cards for storing, splitting, versioning, and tracking data. DataCards currently support <code>pd.DataFrames</code>, <code>np.Arrays</code>, and <code>pyarrow.Tables</code>.</p>"},{"location":"cards/datacard/#features","title":"Features","text":"<ul> <li>shareable: All cards including DataCards are shareable and searchable.</li> <li>auto-schema: Automatic shema detection and feature map creation for features and feature data types.</li> <li>data-conversion: Auto-conversion to either parquet (pa.Table, pd.DataFrame) or zarr (np.Arrays) for fast reading and writing to storage.</li> <li>data_splits: Define split logic for your data to generate splits (i.e., train, test, eval)</li> <li>extra-info: Additional optional arguments that allow you to associate your data with feature descriptions or extra info (sql scripts etc.)</li> <li>versioning: SemVer for your data.</li> </ul>"},{"location":"cards/datacard/#creating-a-card","title":"Creating a Card","text":"<p><pre><code># Data\nfrom sklearn.datasets import load_linnerud\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\n\n# Opsml\nfrom opsml.registry import CardInfo, DataCard, CardRegistry\n\ndata, target = load_linnerud(return_X_y=True, as_frame=True)\ndata[\"Pulse\"] = target.Pulse\n\n\n# Split indices\nindices = np.arange(data.shape[0])\n\n# usual train-val split\ntrain_idx, test_idx = train_test_split(indices, test_size=0.2, train_size=None)\n\ncard_info = CardInfo(name=\"linnerrud\", team=\"opsml\", user_email=\"user@email.com\")\ndata_card = DataCard(\n    info=card_info,\n    data=data,\n    dependent_vars=[\"Pulse\"],\n    # define splits\n    data_splits=[\n        {\"label\": \"train\", \"indices\": train_idx},\n        {\"label\": \"test\", \"indices\": test_idx},\n    ],\n)\n\n# splits look good\nsplits = data_card.split_data()\nprint(splits.train.X.head())\n\n\"\"\"   \n    Chins  Situps  Jumps\n0    5.0   162.0   60.0\n1    2.0   110.0   60.0\n2   12.0   101.0  101.0\n3   12.0   105.0   37.0\n4   13.0   155.0   58.0\n\"\"\"\n\ndata_registry = CardRegistry(registry_name=\"data\")\ndata_registry.register_card(card=data_card)\nprint(data_card.version)\n# &gt; 1.0.0\n\n# list cards\ncards = data_registry.list_cards(\n    uid=data_card.uid, \n    as_dataframe=False,\n    )  # can also supply, name, team, version\nprint(cards[0])\n</code></pre> (Code will run as-is)</p> <p>Output:</p> <pre><code>{\n\"name\": \"linnerrud\",\n\"date\": \"2023-04-28\",\n\"version\": \"1.0.0\",\n\"data_uri\": \"opsml_artifacts/OPSML_DATA_REGISTRY/opsml/linnerrud/v-1.0.0/linnerrud.parquet\",\n\"runcard_uid\": None,\n\"datacard_uri\": \"opsml_artifacts/OPSML_DATA_REGISTRY/opsml/linnerrud/v-1.0.0/datacard.joblib\",\n\"uid\": \"06a28a3bc2504bdd83c20a622439236d\",\n\"app_env\": \"staging\",\n\"timestamp\": 1682699807492552,\n\"team\": \"opsml\",\n\"user_email\": \"user@email.com\",\n\"data_type\": \"DataFrame\",\n\"pipelinecard_uid\": None,\n}\n</code></pre>"},{"location":"cards/datacard/#datacard-args","title":"DataCard Args","text":"<code>data</code> np.ndarray, pd.DataFrame, or pyarrow Table. You're data (Required) <code>name</code> Name for the data (Required) <code>team</code> Team data belongs to (Required) <code>user_email</code> Email to associate with data (Required) <code>sql_logic</code> SQL query or path to sql file containing logic to build data. Required if <code>data</code> is not provided. <code>data_splits</code> <p>Split logic for your data. Optional list containing split logic. Defaults to None.</p> <p>If a dependent variables is specified. Data splits will return X and y data.</p> <p>Logic for data splits can be defined in the following three ways:</p> <p>You can specify as many splits as you'd like</p> <p>(1) Split based on column value (works for pd.DataFrame)</p> <pre><code>splits = [\n    {\"label\": \"train\", \"column\": \"DF_COL\", \"column_value\": 0}, -&gt; \"val\" can also be a string\n    {\"label\": \"test\",  \"column\": \"DF_COL\", \"column_value\": 1},\n    {\"label\": \"eval\",  \"column\": \"DF_COL\", \"column_value\": 2},\n    ]\n</code></pre> <p>(2) Index slicing by start and stop (works for np.ndarray, pyarrow.Table, and pd.DataFrame)</p> <pre><code>splits = [\n    {\"label\": \"train\", \"start\": 0, \"stop\": 10},\n    {\"label\": \"test\", \"start\": 11, \"stop\": 15},\n    ]\n</code></pre> <p>(3) Index slicing by list (works for np.ndarray, pyarrow.Table, and pd.DataFrame)</p> <pre><code>splits = [\n    {\"label\": \"train\", \"indices\": [1,2,3,4]},\n    {\"label\": \"test\", \"indices\": [5,6,7,8]},\n    ]\n</code></pre> <code>feature_descriptions</code> Dictionary contain feature descriptions (key -&gt; feature name, value -&gt; Description) <code>additional_info</code> Dictionary used as storage object for extra information you'd like to provide."},{"location":"cards/datacard/#docs","title":"Docs","text":""},{"location":"cards/datacard/#opsml.registry.DataCard","title":"<code>opsml.registry.DataCard</code>","text":"<p>         Bases: <code>ArtifactCard</code></p> <p>Create a DataCard from your data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <p>Data to use for data card.</p> required <code>name</code> <p>What to name the data</p> required <code>team</code> <p>Team that this data is associated with</p> required <code>user_email</code> <p>Email to associate with data card</p> required <code>dependent_vars</code> <p>Optional list of dependent variables in data</p> required <code>feature_descriptions</code> <p>Optional dictionary of feature names and their descriptions</p> required <code>dependent_vars</code> <p>List of dependent variables. Can be string or index if using numpy</p> required <code>feature_descriptions</code> <p>Dictionary of features and their descriptions</p> required <code>additional_info</code> <p>Dictionary of additional info to associate with data (i.e. if data is tokenized dataset, metadata could be {\"vocab_size\": 200})</p> required <code>data_splits</code> <p>Optional list containing split logic. Defaults to None. Logic for data splits can be defined in the following three ways:</p> <p>You can specify as many splits as you'd like</p> <p>(1) Split based on column value (works for pd.DataFrame)     splits = [         {\"label\": \"train\", \"column\": \"DF_COL\", \"column_value\": 0}, -&gt; \"val\" can also be a string         {\"label\": \"test\",  \"column\": \"DF_COL\", \"column_value\": 1},         {\"label\": \"eval\",  \"column\": \"DF_COL\", \"column_value\": 2},         ]</p> <p>(2) Index slicing by start and stop (works for np.ndarray, pyarrow.Table, and pd.DataFrame)     splits = [         {\"label\": \"train\", \"start\": 0, \"stop\": 10},         {\"label\": \"test\", \"start\": 11, \"stop\": 15},         ]</p> <p>(3) Index slicing by list (works for np.ndarray, pyarrow.Table, and pd.DataFrame)     splits = [         {\"label\": \"train\", \"indices\": [1,2,3,4]},         {\"label\": \"test\", \"indices\": [5,6,7,8]},         ]</p> required <code>runcard_uid</code> <p>Id of RunCard that created the DataCard</p> required <code>pipelinecard_uid</code> <p>Associated PipelineCard</p> required <code>sql_logic</code> <p>Dictionary of strings containing sql logic or sql files used to create the data</p> required <code>data_uri</code> <p>Location where converted pyarrow table is stored</p> required <code>version</code> <p>DataCard version</p> required <code>feature_map</code> <p>Map of features in data (inferred when converting to pyrarrow table)</p> required <code>data_type</code> <p>Data type inferred from supplied data</p> required <code>uid</code> <p>Unique id assigned to the DataCard</p> required <p>Returns:</p> Type Description <p>DataCard</p> Source code in <code>/home/steven_forrester/github/opsml-artifacts/opsml/registry/cards/cards.py</code> <pre><code>class DataCard(ArtifactCard):\n\"\"\"Create a DataCard from your data.\n\n    Args:\n        data:\n            Data to use for data card.\n        name:\n            What to name the data\n        team:\n            Team that this data is associated with\n        user_email:\n            Email to associate with data card\n        dependent_vars:\n            Optional list of dependent variables in data\n        feature_descriptions:\n            Optional dictionary of feature names and their descriptions\n        dependent_vars:\n            List of dependent variables. Can be string or index if using numpy\n        feature_descriptions:\n            Dictionary of features and their descriptions\n        additional_info:\n            Dictionary of additional info to associate with data\n            (i.e. if data is tokenized dataset, metadata could be {\"vocab_size\": 200})\n        data_splits:\n            Optional list containing split logic. Defaults to None.\n            Logic for data splits can be defined in the following three ways:\n\n            You can specify as many splits as you'd like\n\n            (1) Split based on column value (works for pd.DataFrame)\n                splits = [\n                    {\"label\": \"train\", \"column\": \"DF_COL\", \"column_value\": 0}, -&gt; \"val\" can also be a string\n                    {\"label\": \"test\",  \"column\": \"DF_COL\", \"column_value\": 1},\n                    {\"label\": \"eval\",  \"column\": \"DF_COL\", \"column_value\": 2},\n                    ]\n\n            (2) Index slicing by start and stop (works for np.ndarray, pyarrow.Table, and pd.DataFrame)\n                splits = [\n                    {\"label\": \"train\", \"start\": 0, \"stop\": 10},\n                    {\"label\": \"test\", \"start\": 11, \"stop\": 15},\n                    ]\n\n            (3) Index slicing by list (works for np.ndarray, pyarrow.Table, and pd.DataFrame)\n                splits = [\n                    {\"label\": \"train\", \"indices\": [1,2,3,4]},\n                    {\"label\": \"test\", \"indices\": [5,6,7,8]},\n                    ]\n\n        runcard_uid:\n            Id of RunCard that created the DataCard\n\n        pipelinecard_uid:\n            Associated PipelineCard\n\n        sql_logic:\n            Dictionary of strings containing sql logic or sql files used to create the data\n\n        The following are non-required args and are set after registering a DataCard\n\n        data_uri:\n            Location where converted pyarrow table is stored\n        version:\n            DataCard version\n        feature_map:\n            Map of features in data (inferred when converting to pyrarrow table)\n        data_type:\n            Data type inferred from supplied data\n        uid:\n            Unique id assigned to the DataCard\n\n    Returns:\n        DataCard\n\n    \"\"\"\n\n    data: Optional[Union[np.ndarray, pd.DataFrame, Table]]\n    data_splits: Optional[List[Dict[str, Any]]]\n    feature_map: Optional[Dict[str, Union[str, None]]]\n    data_type: Optional[str]\n    dependent_vars: Optional[List[Union[int, str]]]\n    feature_descriptions: Optional[Dict[str, str]]\n    additional_info: Optional[Dict[str, Union[float, int, str]]]\n    sql_logic: Dict[Optional[str], Optional[str]] = {}\n    runcard_uid: Optional[str] = None\n    pipelinecard_uid: Optional[str] = None\n    data_uri: Optional[str]\n    datacard_uri: Optional[str] = None\n\n    @validator(\"data_uri\", pre=True, always=True)\n    def check_data(cls, data_uri, values):  # pylint: disable=no-self-argument\n        if data_uri is None:\n            if values[\"data\"] is None and not bool(values[\"sql_logic\"]):\n                raise ValueError(\"Data or sql logic must be supplied when no data_uri is present\")\n\n        return data_uri\n\n    @validator(\"data_splits\", pre=True, always=True)\n    def check_splits(cls, splits):  # pylint: disable=no-self-argument\n        if splits is None:\n            return []\n\n        for split in splits:\n            indices = split.get(\"indices\")\n            if indices is not None and isinstance(indices, np.ndarray):\n                split[\"indices\"] = indices.tolist()\n\n        return splits\n\n    @validator(\"feature_descriptions\", pre=True, always=True)\n    def lower_descriptions(cls, feature_descriptions):  # pylint: disable=no-self-argument\n        if feature_descriptions is None:\n            return feature_descriptions\n\n        feat_dict = {}\n        for feature, description in feature_descriptions.items():\n            feat_dict[feature.lower()] = description.lower()\n\n        return feat_dict\n\n    @validator(\"additional_info\", pre=True, always=True)\n    def check_info(cls, value):  # pylint: disable=no-self-argument\n        return value or {}\n\n    @validator(\"sql_logic\", pre=True, always=True)\n    def load_sql(cls, sql_logic, values):  # pylint: disable=no-self-argument\n        if not bool(sql_logic):\n            return sql_logic\n\n        for name, query in sql_logic.items():\n            if \".sql\" in query:\n                try:\n                    sql_path = FindPath.find_filepath(name=query)\n                    with open(sql_path, \"r\", encoding=\"utf-8\") as file_:\n                        query_ = file_.read()\n                    sql_logic[name] = query_\n\n                except Exception as error:\n                    raise ValueError(f\"Could not load sql file {query}. {error}\") from error\n\n        return sql_logic\n\n    def split_data(self) -&gt; Optional[DataHolder]:\n\"\"\"\n        Loops through data splits and splits data either by indexing or\n        column values\n\n        Example:\n\n            ```python\n            card_info = CardInfo(name=\"linnerrud\", team=\"tutorial\", user_email=\"user@email.com\")\n            data_card = DataCard(\n                info=card_info,\n                data=data,\n                dependent_vars=[\"Pulse\"],\n                # define splits\n                data_splits=[\n                    {\"label\": \"train\", \"indices\": train_idx},\n                    {\"label\": \"test\", \"indices\": test_idx},\n                ],\n\n            )\n\n            splits = data_card.split_data()\n            print(splits.train.X.head())\n\n               Chins  Situps  Jumps\n            0    5.0   162.0   60.0\n            1    2.0   110.0   60.0\n            2   12.0   101.0  101.0\n            3   12.0   105.0   37.0\n            4   13.0   155.0   58.0\n            ```\n\n        Returns\n            Class containing data splits\n        \"\"\"\n\n        if self.data_splits is not None:\n            data_holder = DataHolder()\n            for split in self.data_splits:\n                label, data = DataSplitter(\n                    split_attributes=split,\n                    dependent_vars=self.dependent_vars,\n                ).split(data=self.data)\n\n                setattr(data_holder, label, data)\n\n            return data_holder\n        raise ValueError(\"No data splits provided\")\n\n    def load_data(self):\n\"\"\"Loads data\"\"\"\n\n        if not bool(self.data) and self.storage_client is not None:\n            storage_spec = ArtifactStorageSpecs(save_path=self.data_uri)\n\n            self.storage_client.storage_spec = storage_spec\n            data = load_record_artifact_from_storage(\n                storage_client=self.storage_client,\n                artifact_type=self.data_type,\n            )\n\n            setattr(self, \"data\", data)\n        else:\n            logger.info(\"Data has already been loaded\")\n\n    def create_registry_record(self) -&gt; RegistryRecord:\n\"\"\"\n        Creates required metadata for registering the current data card.\n        Implemented with a DataRegistry object.\n\n        Returns:\n            Regsitry metadata\n\n        \"\"\"\n        exclude_attr = {\"data\", \"storage_client\"}\n        return DataRegistryRecord(**self.dict(exclude=exclude_attr))\n\n    def add_info(self, info: Dict[str, Union[float, int, str]]):\n\"\"\"\n        Adds metadata to the existing DataCard metadatda dictionary\n\n        Args:\n            Metadata:\n                Dictionary containing name (str) and value (float, int, str) pairs\n                to add to the current metadata set\n        \"\"\"\n\n        curr_info = cast(Dict[str, Union[int, float, str]], self.additional_info)\n        self.additional_info = {**info, **curr_info}\n\n    def add_sql(\n        self,\n        name: str,\n        query: Optional[str] = None,\n        filename: Optional[str] = None,\n    ):\n\"\"\"\n        Adds a query or query from file to the sql_logic dictionary. Either a query or\n        a filename pointing to a sql file are required in addition to a name.\n\n        Args:\n            name:\n                Name for sql query\n            query:\n                SQL query\n            filename:\n                Filename of sql query\n        \"\"\"\n        if query is not None:\n            self.sql_logic[name] = query\n\n        elif filename is not None:\n            sql_path = FindPath.find_filepath(name=filename)\n            with open(sql_path, \"r\", encoding=\"utf-8\") as file_:\n                query = file_.read()\n            self.sql_logic[name] = query\n\n        else:\n            raise ValueError(\"SQL Query or Filename must be provided\")\n\n    @property\n    def card_type(self) -&gt; str:\n        return CardType.DATACARD.value\n</code></pre>"},{"location":"cards/datacard/#opsml.registry.cards.cards.DataCard.card_type","title":"<code>card_type: str</code>  <code>property</code>","text":""},{"location":"cards/datacard/#opsml.registry.cards.cards.DataCard.split_data","title":"<code>split_data()</code>","text":"<p>Loops through data splits and splits data either by indexing or column values</p> Example <pre><code>card_info = CardInfo(name=\"linnerrud\", team=\"tutorial\", user_email=\"user@email.com\")\ndata_card = DataCard(\n    info=card_info,\n    data=data,\n    dependent_vars=[\"Pulse\"],\n    # define splits\n    data_splits=[\n        {\"label\": \"train\", \"indices\": train_idx},\n        {\"label\": \"test\", \"indices\": test_idx},\n    ],\n\n)\n\nsplits = data_card.split_data()\nprint(splits.train.X.head())\n\n   Chins  Situps  Jumps\n0    5.0   162.0   60.0\n1    2.0   110.0   60.0\n2   12.0   101.0  101.0\n3   12.0   105.0   37.0\n4   13.0   155.0   58.0\n</code></pre> <p>Returns     Class containing data splits</p> Source code in <code>/home/steven_forrester/github/opsml-artifacts/opsml/registry/cards/cards.py</code> <pre><code>def split_data(self) -&gt; Optional[DataHolder]:\n\"\"\"\n    Loops through data splits and splits data either by indexing or\n    column values\n\n    Example:\n\n        ```python\n        card_info = CardInfo(name=\"linnerrud\", team=\"tutorial\", user_email=\"user@email.com\")\n        data_card = DataCard(\n            info=card_info,\n            data=data,\n            dependent_vars=[\"Pulse\"],\n            # define splits\n            data_splits=[\n                {\"label\": \"train\", \"indices\": train_idx},\n                {\"label\": \"test\", \"indices\": test_idx},\n            ],\n\n        )\n\n        splits = data_card.split_data()\n        print(splits.train.X.head())\n\n           Chins  Situps  Jumps\n        0    5.0   162.0   60.0\n        1    2.0   110.0   60.0\n        2   12.0   101.0  101.0\n        3   12.0   105.0   37.0\n        4   13.0   155.0   58.0\n        ```\n\n    Returns\n        Class containing data splits\n    \"\"\"\n\n    if self.data_splits is not None:\n        data_holder = DataHolder()\n        for split in self.data_splits:\n            label, data = DataSplitter(\n                split_attributes=split,\n                dependent_vars=self.dependent_vars,\n            ).split(data=self.data)\n\n            setattr(data_holder, label, data)\n\n        return data_holder\n    raise ValueError(\"No data splits provided\")\n</code></pre>"},{"location":"cards/datacard/#opsml.registry.cards.cards.DataCard.load_data","title":"<code>load_data()</code>","text":"<p>Loads data</p> Source code in <code>/home/steven_forrester/github/opsml-artifacts/opsml/registry/cards/cards.py</code> <pre><code>def load_data(self):\n\"\"\"Loads data\"\"\"\n\n    if not bool(self.data) and self.storage_client is not None:\n        storage_spec = ArtifactStorageSpecs(save_path=self.data_uri)\n\n        self.storage_client.storage_spec = storage_spec\n        data = load_record_artifact_from_storage(\n            storage_client=self.storage_client,\n            artifact_type=self.data_type,\n        )\n\n        setattr(self, \"data\", data)\n    else:\n        logger.info(\"Data has already been loaded\")\n</code></pre>"},{"location":"cards/modelcard/","title":"ModelCard","text":"<p>ModelCards are cards for storing, versioning, and tracking model objects.</p>"},{"location":"cards/modelcard/#features","title":"Features","text":"<ul> <li>shareable: All cards including ModelCards are shareable and searchable.</li> <li>auto-onnx: Automatic conversion of trained model into onnx model format and associated onnx-model api definition. Currenlty supports <code>lightgbm</code>, <code>xgboost</code>, <code>sklearn</code> and most flavors of <code>Tensorflow</code>, <code>Pytorch</code> and <code>HuggingFace</code>.</li> <li>auto-schema: Auto-infer data schema and input and output signature.</li> <li>versioning: SemVer for your model.</li> </ul>"},{"location":"cards/modelcard/#create-a-card","title":"Create a Card","text":"<p><pre><code># load data card from earlier\nfrom sklearn.linear_model import LinearRegression\n\n# Opsml\nfrom opsml.registry import CardRegistry, ModelCard, CardInfo\n\n# set up registries\ndata_registry = CardRegistry(registry_name=\"data\")\nmodel_registry = CardRegistry(registry_name=\"model\")\n\ncard_info = CardInfo(name=\"linnerrud\", team=\"opsml\", user_email=\"user@email.com\")\n\n\n# load datacard\ndatacard = data_registry.load_card(name=card_info.name, team=card_info.team, version=\"1.0.0\")\n\n# data is not loaded by default (helps when sharing cards with large data)\ndatacard.load_data()\ndata_splits = datacard.split_data()\n\n\nX_train = data_splits.train\ny_train = data_splits.train.pop(datacard.dependent_vars[0])\n\n# fit model\nlinreg = LinearRegression()\nlinreg = linreg.fit(X=X_train, y=y_train)\n\n# lets test the onnx model before registering\nmodelcard = ModelCard(\n    info=card_info,\n    trained_model=linreg,\n    sample_input_data=X_train,\n    datacard_uid=datacard.uid,\n)\n\nonnx_predictor = modelcard.onnx_model()\nrecord = list(modelcard.sample_input_data[0:1].T.to_dict().values())[0]\n\npred_onnx = onnx_predictor.predict(record)[\"variable\"]\npred_orig = onnx_predictor.predict_with_model(linreg, record)[0][0]\n\nprint(f\"Original: {pred_orig}, Onnx: {pred_onnx}\")\n# &gt; Original: 54.4616866, Onnx: 54.4616866\n\nprint(onnx_predictor.input_sig.schema_json())\nprint(onnx_predictor.output_sig.schema_json())\n\n# everything looks good\nmodel_registry.register_card(modelcard)\n</code></pre> (code requires DataCard to be registered. Refer to homepage example)</p> <p>Outputs </p> <pre><code># input sig\n{\n\"title\": \"Features\",\n\"type\": \"object\",\n\"properties\": {\n\"Chins\": {\"title\": \"Chins\", \"type\": \"number\"},\n\"Situps\": {\"title\": \"Situps\", \"type\": \"number\"},\n\"Jumps\": {\"title\": \"Jumps\", \"type\": \"number\"},\n},\n\"required\": [\"Chins\", \"Situps\", \"Jumps\"],\n}\n\n# output sig\n{\n\"title\": \"Features\",\n\"type\": \"object\",\n\"properties\": {\"variable\": {\"title\": \"Variable\", \"type\": \"number\"}},\n\"required\": [\"variable\"],\n}\n</code></pre>"},{"location":"cards/modelcard/#modelcard-args","title":"ModelCard Args","text":"<code>trained_model</code> You're trained model (Required) <code>sample_input_data</code> Sample of data used to train model (Required) <code>name</code> Name for the model (Required) <code>team</code> Team model belongs to (Required) <code>user_email</code> Email to associate with model (Required) <code>datacard_uid</code> uid of DataCard that contains training data. This is not required to instantiate a ModelCard, but it is required to register a ModelCard <code>datacard_uid</code> uid of DataCard that contains training data. This is not required to instantiate a ModelCard, but it is required to register a ModelCard <code>to_onnx</code> Whether to convert model to onnx or not. Default is True"},{"location":"cards/modelcard/#docs","title":"Docs","text":""},{"location":"cards/modelcard/#opsml.registry.ModelCard","title":"<code>opsml.registry.ModelCard</code>","text":"<p>         Bases: <code>ArtifactCard</code></p> <p>Create a ModelCard from your trained machine learning model. This Card is used in conjunction with the ModelCardCreator class.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <p>Name for the model specific to your current project</p> required <code>team</code> <p>Team that this model is associated with</p> required <code>user_email</code> <p>Email to associate with card</p> required <code>trained_model</code> <p>Trained model. Can be of type sklearn, xgboost, lightgbm or tensorflow</p> required <code>sample_input_data</code> <p>Sample of data model was trained on</p> required <code>uid</code> <p>Unique id (assigned if card has been registered)</p> required <code>version</code> <p>Current version (assigned if card has been registered)</p> required <code>datacard_uid</code> <p>Uid of the DataCard associated with training the model</p> required <code>onnx_model_data</code> <p>Pydantic model containing onnx data schema</p> required <code>onnx_model_def</code> <p>Pydantic model containing OnnxModel definition</p> required <code>model_type</code> <p>Type of model</p> required <code>data_schema</code> <p>Optional dictionary of the data schema used in model training</p> required <code>additional_onnx_args</code> <p>Optional pydantic model containing Torch args for model conversion to onnx.</p> required <code>runcard_uid</code> <p>RunCard associated with the ModelCard</p> required <code>pipelinecard_uid</code> <p>Associated PipelineCard</p> required <code>uris</code> <p>modelcard_uri:     URI of modelcard trained_model_uri:     URI where model is stored sample_data_uri:     URI of trained model sample data model_metadata_uri:     URI where model metadata is stored</p> required Source code in <code>/home/steven_forrester/github/opsml-artifacts/opsml/registry/cards/cards.py</code> <pre><code>class ModelCard(ArtifactCard):\n\"\"\"Create a ModelCard from your trained machine learning model.\n    This Card is used in conjunction with the ModelCardCreator class.\n\n    Args:\n        name:\n            Name for the model specific to your current project\n        team:\n            Team that this model is associated with\n        user_email:\n            Email to associate with card\n        trained_model:\n            Trained model. Can be of type sklearn, xgboost, lightgbm or tensorflow\n        sample_input_data:\n            Sample of data model was trained on\n        uid:\n            Unique id (assigned if card has been registered)\n        version:\n            Current version (assigned if card has been registered)\n        datacard_uid:\n            Uid of the DataCard associated with training the model\n        onnx_model_data:\n            Pydantic model containing onnx data schema\n        onnx_model_def:\n            Pydantic model containing OnnxModel definition\n        model_type:\n            Type of model\n        data_schema:\n            Optional dictionary of the data schema used in model training\n        additional_onnx_args:\n            Optional pydantic model containing Torch args for model conversion to onnx.\n        runcard_uid:\n            RunCard associated with the ModelCard\n        pipelinecard_uid:\n            Associated PipelineCard\n        uris:\n            modelcard_uri:\n                URI of modelcard\n            trained_model_uri:\n                URI where model is stored\n            sample_data_uri:\n                URI of trained model sample data\n            model_metadata_uri:\n                URI where model metadata is stored\n    \"\"\"\n\n    trained_model: Optional[Any]\n    sample_input_data: Optional[Union[pd.DataFrame, np.ndarray, Dict[str, np.ndarray]]]\n    datacard_uid: Optional[str]\n    onnx_model_data: Optional[DataDict]\n    onnx_model_def: Optional[OnnxModelDefinition]\n    sample_data_type: Optional[str]\n    model_type: Optional[str]\n    additional_onnx_args: Optional[TorchOnnxArgs]\n    data_schema: Optional[ApiDataSchemas]\n    runcard_uid: Optional[str] = None\n    pipelinecard_uid: Optional[str] = None\n    to_onnx: bool = True\n    uris: ModelCardUris = ModelCardUris()\n\n    class Config:\n        arbitrary_types_allowed = True\n        keep_untouched = (cached_property,)\n\n    @root_validator(pre=True)\n    def check_args(cls, values: Dict[str, Any]):  # pylint: disable=no-self-argument\n\"\"\"Converts trained model to modelcard\"\"\"\n\n        if all([values.get(\"uid\"), values.get(\"version\")]):\n            return values\n\n        if not cls._required_args_present(values=values):\n            raise ValueError(\n\"\"\"trained_model and sample_input_data are required for instantiating a ModelCard\"\"\",\n            )\n\n        return values\n\n    @classmethod\n    def _required_args_present(cls, values: Dict[str, Any]) -&gt; bool:\n        return all(\n            values.get(var_) is not None\n            for var_ in [\n                \"trained_model\",\n                \"sample_input_data\",\n            ]\n        )\n\n    @property\n    def model_data_schema(self) -&gt; DataDict:\n        if self.data_schema is not None:\n            return self.data_schema.model_data_schema\n        raise ValueError(\"Model data schema has not been set\")\n\n    @property\n    def input_data_schema(self) -&gt; Dict[str, Feature]:\n        if self.data_schema is not None and self.data_schema.input_data_schema is not None:\n            return self.data_schema.input_data_schema\n        raise ValueError(\"Model input data schema has not been set or is not needed for this model\")\n\n    def load_sample_data(self):\n\"\"\"Loads sample data associated with original non-onnx model\"\"\"\n\n        storage_spec = ArtifactStorageSpecs(save_path=self.uris.sample_data_uri)\n\n        self.storage_client.storage_spec = storage_spec\n        sample_data = load_record_artifact_from_storage(\n            storage_client=self.storage_client,\n            artifact_type=self.sample_data_type,\n        )\n\n        setattr(self, \"sample_input_data\", sample_data)\n\n    def load_trained_model(self):\n\"\"\"Loads original trained model\"\"\"\n\n        if not all([bool(self.uris.trained_model_uri), bool(self.uris.sample_data_uri)]):\n            raise ValueError(\n\"\"\"Trained model uri and sample data uri must both be set to load a trained model\"\"\",\n            )\n\n        if self.storage_client is not None:\n            self.load_sample_data()\n            storage_spec = ArtifactStorageSpecs(save_path=self.uris.trained_model_uri)\n            self.storage_client.storage_spec = storage_spec\n            trained_model = load_record_artifact_from_storage(\n                storage_client=self.storage_client,\n                artifact_type=self.model_type,\n            )\n\n            setattr(self, \"trained_model\", trained_model)\n\n    def _load_metadata(self, storage_client: StorageClientType) -&gt; ModelMetadata:\n\"\"\"Loads onnx metadata\"\"\"\n\n        # get metadata\n        storage_spec = ArtifactStorageSpecs(save_path=self.uris.model_metadata_uri)\n        storage_client.storage_spec = storage_spec\n        model_metadata = load_record_artifact_from_storage(\n            storage_client=storage_client,\n            artifact_type=ArtifactStorageType.JSON.value,\n        )\n\n        return ModelMetadata.parse_obj(model_metadata)\n\n    def _load_onnx_model(self, metadata: ModelMetadata, storage_client: StorageClientType) -&gt; Any:\n\"\"\"Loads the actual onnx file\"\"\"\n        # get onnx model\n\n        if metadata.onnx_uri is not None:\n            storage_client.storage_spec.save_path = metadata.onnx_uri\n            onnx_model = load_record_artifact_from_storage(\n                storage_client=storage_client,\n                artifact_type=ArtifactStorageType.ONNX.value,\n            )\n\n            return onnx_model\n\n        raise ValueError(\"Onnx uri is not specified\")\n\n    def load_onnx_model_definition(self):\n\"\"\"Loads the onnx model definition\"\"\"\n\n        if self.uris.model_metadata_uri is None:\n            raise ValueError(\"No model metadata exists. Please check the registry or register a new model\")\n\n        if self.storage_client is not None:\n            metadata = self._load_metadata(storage_client=self.storage_client)\n\n            onnx_model = self._load_onnx_model(\n                metadata=metadata,\n                storage_client=self.storage_client,\n            )\n\n            model_def = OnnxModelDefinition(\n                onnx_version=metadata.onnx_version,\n                model_bytes=onnx_model.SerializeToString(),\n            )\n\n            setattr(self, \"onnx_model_def\", model_def)\n\n    def create_registry_record(self) -&gt; RegistryRecord:\n\"\"\"\n        Creates a registry record from the current ModelCard\n\n        Args:\n            registry_name:\n                ModelCard Registry table making request\n            uid:\n                Unique id of ModelCard\n\n        \"\"\"\n\n        exclude_vars = {\n            \"trained_model\",\n            \"sample_input_data\",\n            \"onnx_model_def\",\n            \"storage_client\",\n        }\n\n        if not bool(self.onnx_model_def):\n            self._create_and_set_model_attr(to_onnx=self.to_onnx)\n\n        return ModelRegistryRecord(**self.dict(exclude=exclude_vars))\n\n    def _set_version_for_predictor(self) -&gt; str:\n        if self.version is None:\n            logger.warning(\n\"\"\"ModelCard has no version (not registered).\n                Defaulting to 1 (for testing only)\n            \"\"\"\n            )\n            version = \"1.0.0\"\n        else:\n            version = self.version\n\n        return version\n\n    def _set_model_attributes(self, model_return: ModelReturn) -&gt; None:\n        setattr(self, \"onnx_model_def\", model_return.model_definition)\n        setattr(self, \"data_schema\", model_return.api_data_schema)\n        setattr(self, \"model_type\", model_return.model_type)\n\n    def _create_and_set_model_attr(self, to_onnx: bool) -&gt; None:\n\"\"\"\n        Creates Onnx model from trained model and sample input data\n        and sets Card attributes\n\n        Args:\n            to_onnx:\n                Whether to convert to onnx or not\n        \"\"\"\n        from opsml.model.creator import (  # pylint: disable=import-outside-toplevel\n            create_model,\n        )\n\n        model_return = create_model(\n            model=self.trained_model,\n            input_data=self.sample_input_data,\n            additional_onnx_args=self.additional_onnx_args,\n            to_onnx=self.to_onnx,\n        )\n\n        self._set_model_attributes(model_return=model_return)\n\n    def _get_sample_data_for_api(self) -&gt; Dict[str, Any]:\n\"\"\"\n        Converts sample data to dictionary that can be used\n        to validate an onnx model\n        \"\"\"\n\n        if self.sample_input_data is None:\n            self.load_sample_data()\n\n        sample_data = cast(\n            Union[pd.DataFrame, np.ndarray, Dict[str, Any]],\n            self.sample_input_data,\n        )\n\n        if isinstance(sample_data, np.ndarray):\n            model_data = self.model_data_schema\n            input_name = next(iter(model_data.input_features.keys()))\n            return {input_name: sample_data[0, :].tolist()}\n\n        if isinstance(sample_data, pd.DataFrame):\n            record = list(sample_data[0:1].T.to_dict().values())[0]\n            return record\n\n        record = {}\n        for feat, val in sample_data.items():\n            record[feat] = np.ravel(val).tolist()\n        return record\n\n    def onnx_model(\n        self,\n        start_onnx_runtime: bool = True,\n    ) -&gt; OnnxModelPredictor:\n\"\"\"\n        Loads an onnx model from string or creates an onnx model from trained model\n\n        Args:\n            start_onnx_runtime:\n                Whether to start the onnx runtime session or not\n\n        Returns\n            `OnnxModelPredictor`\n\n        \"\"\"\n        # todo: clean this up\n        if not bool(self.onnx_model_def):\n            self._create_and_set_model_attr(to_onnx=False)\n\n        version = self._set_version_for_predictor()\n\n        # recast to make mypy happy\n        # todo: refactor\n        model_def = cast(OnnxModelDefinition, self.onnx_model_def)\n        model_type = str(self.model_type)\n        data_schema = cast(ApiDataSchemas, self.data_schema)\n\n        sample_api_data = self._get_sample_data_for_api()\n\n        return OnnxModelPredictor(\n            model_name=self.name,\n            model_type=model_type,\n            model_definition=model_def.model_bytes,\n            data_schema=data_schema,\n            model_version=version,\n            onnx_version=model_def.onnx_version,\n            sample_api_data=sample_api_data,\n            start_sess=start_onnx_runtime,\n        )\n\n    @property\n    def card_type(self) -&gt; str:\n        return CardType.MODELCARD.value\n</code></pre>"},{"location":"cards/modelcard/#opsml.registry.cards.cards.ModelCard.load_sample_data","title":"<code>load_sample_data()</code>","text":"<p>Loads sample data associated with original non-onnx model</p> Source code in <code>/home/steven_forrester/github/opsml-artifacts/opsml/registry/cards/cards.py</code> <pre><code>def load_sample_data(self):\n\"\"\"Loads sample data associated with original non-onnx model\"\"\"\n\n    storage_spec = ArtifactStorageSpecs(save_path=self.uris.sample_data_uri)\n\n    self.storage_client.storage_spec = storage_spec\n    sample_data = load_record_artifact_from_storage(\n        storage_client=self.storage_client,\n        artifact_type=self.sample_data_type,\n    )\n\n    setattr(self, \"sample_input_data\", sample_data)\n</code></pre>"},{"location":"cards/modelcard/#opsml.registry.cards.cards.ModelCard.load_trained_model","title":"<code>load_trained_model()</code>","text":"<p>Loads original trained model</p> Source code in <code>/home/steven_forrester/github/opsml-artifacts/opsml/registry/cards/cards.py</code> <pre><code>def load_trained_model(self):\n\"\"\"Loads original trained model\"\"\"\n\n    if not all([bool(self.uris.trained_model_uri), bool(self.uris.sample_data_uri)]):\n        raise ValueError(\n\"\"\"Trained model uri and sample data uri must both be set to load a trained model\"\"\",\n        )\n\n    if self.storage_client is not None:\n        self.load_sample_data()\n        storage_spec = ArtifactStorageSpecs(save_path=self.uris.trained_model_uri)\n        self.storage_client.storage_spec = storage_spec\n        trained_model = load_record_artifact_from_storage(\n            storage_client=self.storage_client,\n            artifact_type=self.model_type,\n        )\n\n        setattr(self, \"trained_model\", trained_model)\n</code></pre>"},{"location":"cards/modelcard/#opsml.registry.cards.cards.ModelCard.load_onnx_model_definition","title":"<code>load_onnx_model_definition()</code>","text":"<p>Loads the onnx model definition</p> Source code in <code>/home/steven_forrester/github/opsml-artifacts/opsml/registry/cards/cards.py</code> <pre><code>def load_onnx_model_definition(self):\n\"\"\"Loads the onnx model definition\"\"\"\n\n    if self.uris.model_metadata_uri is None:\n        raise ValueError(\"No model metadata exists. Please check the registry or register a new model\")\n\n    if self.storage_client is not None:\n        metadata = self._load_metadata(storage_client=self.storage_client)\n\n        onnx_model = self._load_onnx_model(\n            metadata=metadata,\n            storage_client=self.storage_client,\n        )\n\n        model_def = OnnxModelDefinition(\n            onnx_version=metadata.onnx_version,\n            model_bytes=onnx_model.SerializeToString(),\n        )\n\n        setattr(self, \"onnx_model_def\", model_def)\n</code></pre>"},{"location":"cards/modelcard/#opsml.registry.cards.cards.ModelCard.onnx_model","title":"<code>onnx_model(start_onnx_runtime=True)</code>","text":"<p>Loads an onnx model from string or creates an onnx model from trained model</p> <p>Parameters:</p> Name Type Description Default <code>start_onnx_runtime</code> <code>bool</code> <p>Whether to start the onnx runtime session or not</p> <code>True</code> <p>Returns     <code>OnnxModelPredictor</code></p> Source code in <code>/home/steven_forrester/github/opsml-artifacts/opsml/registry/cards/cards.py</code> <pre><code>def onnx_model(\n    self,\n    start_onnx_runtime: bool = True,\n) -&gt; OnnxModelPredictor:\n\"\"\"\n    Loads an onnx model from string or creates an onnx model from trained model\n\n    Args:\n        start_onnx_runtime:\n            Whether to start the onnx runtime session or not\n\n    Returns\n        `OnnxModelPredictor`\n\n    \"\"\"\n    # todo: clean this up\n    if not bool(self.onnx_model_def):\n        self._create_and_set_model_attr(to_onnx=False)\n\n    version = self._set_version_for_predictor()\n\n    # recast to make mypy happy\n    # todo: refactor\n    model_def = cast(OnnxModelDefinition, self.onnx_model_def)\n    model_type = str(self.model_type)\n    data_schema = cast(ApiDataSchemas, self.data_schema)\n\n    sample_api_data = self._get_sample_data_for_api()\n\n    return OnnxModelPredictor(\n        model_name=self.name,\n        model_type=model_type,\n        model_definition=model_def.model_bytes,\n        data_schema=data_schema,\n        model_version=version,\n        onnx_version=model_def.onnx_version,\n        sample_api_data=sample_api_data,\n        start_sess=start_onnx_runtime,\n    )\n</code></pre>"},{"location":"cards/overview/","title":"Overview","text":"<p>Cards (aka Artifact Cards) are one of the primary interfaces for working with <code>Opsml</code>.</p> <p> </p>"},{"location":"cards/overview/#card-types","title":"Card Types","text":"<ul> <li><code>DataCard</code>: Card used to store data-related information (data, dependent variables, feature descriptions, split logic, etc.)</li> <li><code>ModelCard</code>: Card used to store trained model and model information</li> <li><code>RunCard</code>: Stores artifact and metric info related to Data, Model, or Pipeline cards.</li> <li><code>PipelineCard</code>: Stores information related to a training pipeline and all other cards created within the pipeline (Data, Run, Model)</li> <li><code>ProjectCard</code>: Stores information related to unique projects. You will most likely never interact with this card directly.</li> </ul>"},{"location":"cards/overview/#registries","title":"Registries","text":"<p>Each card type is associated with a specific registry (<code>DataCard</code> with data registry, <code>ModelCard</code> with model registry, etc.), and registries can be used to <code>list</code>, <code>load</code> and <code>register</code> cards.</p>"},{"location":"cards/overview/#listing-cards","title":"Listing Cards","text":"Return either a list of dictionaries or a dataframe containing card metadata. <p>Required Args:</p> <ul> <li>Name: Name of card (Optional)</li> <li>Team: Team associated with card (Optional)</li> <li>Version: Version of Card (Optional)</li> <li>uid: Uid of card (Optional)</li> <li>info: <code>CardInfo</code> dataclass that can be used in place of Name, Team, Version and Uid</li> <li>limit: Limit result</li> <li>as_dataframe: Returns a dataframe if true else list of dictionaries</li> </ul> <p>Example:</p> <pre><code>from opsml.registry import CardRegistry\n\nregistry = CardRegistry(registry_name=\"model\") # can be \"data\", \"model\", \"run\", \"pipeline\n\n# examples\nregistry.list_cards() \n# will list all cards in registry\n\nregistry.list_cards(limit=10) \n# will list cards and limit the result to 10\n\nregistry.list_cards(name=\"linear-reg\")\n  # list all cards with name \"linear-reg\"\n\nregistry.list_cards(name=\"linear-reg\", team=\"opsml\") \n# list all cards with name \"linear-reg\" with team \"opsml\"\n\nregistry.list_cards(name=\"linear-reg\", team=\"opsml\", version=\"1.0.0\") \n# list card with name \"linear-reg\" with team \"opsml\" and version 1.0.0\n\nregistry.list_cards(name=\"linear-reg\", team=\"opsml\", version=\"1.*.*\") \n# list cards with name \"linear-reg\" with team \"opsml\" and major version of \"1\"\n\nregistry.list_cards(name=\"linear-reg\", team=\"opsml\", version=\"^2.3.4\") \n# list card with name \"linear-reg\" with team \"opsml\" and latest version &lt; 3.0.0\n\nregistry.list_cards(name=\"linear-reg\", team=\"opsml\", version=\"~2.3.4\") \n# list card with name \"linear-reg\" with team \"opsml\" and latest version &lt; 2.4.0\n\nregistry.list_cards(uid=uid, as_dataframe=False)\n# list card by uid\n# will return a list of dictionaries instead of a dataframe\n</code></pre>"},{"location":"cards/overview/#loading-cards","title":"Loading Cards","text":"Load an Artifact card from a registry. <p>Required Args:</p> <ul> <li>Name: Name of card (Optional)</li> <li>Team: Team associated with card (Optional)</li> <li>Version: Version of Card (Optional)</li> <li>uid: Uid of card (Optional)</li> <li>info: <code>CardInfo</code> dataclass that can be used in place of Name, Team, Version and Uid</li> </ul> <pre><code>  from opsml.registry import CardRegistry\n  model_regitstry = CardRegistry(registry_name=\"model\")\n\n  example_record = model_regitstry.list_cards(name=\"linnerrud\", as_dataframe=False)[0]\n\n  model_card = model_regitstry.load_card(uid=example_record.get(\"uid\"))\n  print(model_card.version)\n  #&gt; 1.0.0\n</code></pre>"},{"location":"cards/overview/#registering-a-card","title":"Registering a Card","text":"Register a card to a registry <p>Required Args:</p> <ul> <li>card: Card to register</li> <li>version_type: Type of version increment. Can be \"major\", \"minor\" and \"patch\" (Optional)</li> <li>save_path: Specific path to save to in root opsml folder if default are not preferred (Optional)</li> </ul> <pre><code>  from opsml.registry import CardRegistry\n\n  model_registry = CardRegistry(registry_name=\"model\")\n\n  example_record = model_registry.list_cards(name=\"linnerrud\", as_dataframe=False)[0]\n\n  model_card = model_registry.load_card(uid=example_record.get(\"uid\"))\n  print(model_card.version)\n  #&gt; 1.0.0\n</code></pre>"},{"location":"cards/pipeline_card/","title":"PipelineCard","text":""},{"location":"cards/pipeline_card/#opsml.registry.PipelineCard","title":"<code>opsml.registry.PipelineCard</code>","text":"<p>         Bases: <code>ArtifactCard</code></p> <p>Create a PipelineCard from specified arguments</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <p>Pipeline name</p> required <code>team</code> <p>Team that this card is associated with</p> required <code>user_email</code> <p>Email to associate with card</p> required <code>uid</code> <p>Unique id (assigned if card has been registered)</p> required <code>version</code> <p>Current version (assigned if card has been registered)</p> required <code>pipeline_code_uri</code> <p>Storage uri of pipeline code</p> required <code>datacard_uids</code> <p>Optional list of DataCard uids to associate with pipeline</p> required <code>modelcard_uids</code> <p>Optional list of ModelCard uids to associate with pipeline</p> required <code>runcard_uids</code> <p>Optional list of RunCard uids to associate with pipeline</p> required Source code in <code>/home/steven_forrester/github/opsml-artifacts/opsml/registry/cards/cards.py</code> <pre><code>class PipelineCard(ArtifactCard):\n\"\"\"Create a PipelineCard from specified arguments\n\n    Args:\n        name:\n            Pipeline name\n        team:\n            Team that this card is associated with\n        user_email:\n            Email to associate with card\n        uid:\n            Unique id (assigned if card has been registered)\n        version:\n            Current version (assigned if card has been registered)\n        pipeline_code_uri:\n            Storage uri of pipeline code\n        datacard_uids:\n            Optional list of DataCard uids to associate with pipeline\n        modelcard_uids:\n            Optional list of ModelCard uids to associate with pipeline\n        runcard_uids:\n            Optional list of RunCard uids to associate with pipeline\n\n    \"\"\"\n\n    pipeline_code_uri: Optional[str] = None\n    datacard_uids: List[Optional[str]] = []\n    modelcard_uids: List[Optional[str]] = []\n    runcard_uids: List[Optional[str]] = []\n\n    def add_card_uid(self, uid: str, card_type: str):\n\"\"\"\n        Adds Card uid to appropriate card type attribute\n\n        Args:\n            uid:\n                Card uid\n            card_type:\n                Card type. Accepted values are \"data\", \"model\", \"run\"\n        \"\"\"\n        card_type = card_type.lower()\n        if card_type.lower() not in [CardType.DATACARD.value, CardType.RUNCARD.value, CardType.MODELCARD.value]:\n            raise ValueError(\"\"\"Only 'model', 'run' and 'data' are allowed values for card_type\"\"\")\n\n        current_ids = getattr(self, f\"{card_type}card_uids\")\n        new_ids = [*current_ids, *[uid]]\n        setattr(self, f\"{card_type}card_uids\", new_ids)\n\n    def load_pipeline_code(self):\n        raise NotImplementedError\n\n    def create_registry_record(self) -&gt; RegistryRecord:\n\"\"\"Creates a registry record from the current PipelineCard\"\"\"\n        return PipelineRegistryRecord(**self.dict())\n\n    @property\n    def card_type(self) -&gt; str:\n        return CardType.PIPELINECARD.value\n</code></pre>"},{"location":"cards/pipeline_card/#opsml.registry.cards.cards.PipelineCard.add_card_uid","title":"<code>add_card_uid(uid, card_type)</code>","text":"<p>Adds Card uid to appropriate card type attribute</p> <p>Parameters:</p> Name Type Description Default <code>uid</code> <code>str</code> <p>Card uid</p> required <code>card_type</code> <code>str</code> <p>Card type. Accepted values are \"data\", \"model\", \"run\"</p> required Source code in <code>/home/steven_forrester/github/opsml-artifacts/opsml/registry/cards/cards.py</code> <pre><code>def add_card_uid(self, uid: str, card_type: str):\n\"\"\"\n    Adds Card uid to appropriate card type attribute\n\n    Args:\n        uid:\n            Card uid\n        card_type:\n            Card type. Accepted values are \"data\", \"model\", \"run\"\n    \"\"\"\n    card_type = card_type.lower()\n    if card_type.lower() not in [CardType.DATACARD.value, CardType.RUNCARD.value, CardType.MODELCARD.value]:\n        raise ValueError(\"\"\"Only 'model', 'run' and 'data' are allowed values for card_type\"\"\")\n\n    current_ids = getattr(self, f\"{card_type}card_uids\")\n    new_ids = [*current_ids, *[uid]]\n    setattr(self, f\"{card_type}card_uids\", new_ids)\n</code></pre>"},{"location":"cards/runcard/","title":"RunCard","text":"<p><code>RunCards</code> are use to store metrics and artifacts related to <code>DataCards</code>, <code>ModelCards</code> and <code>PipelineCards</code>. While a RunCard can be used as a object itself, it's best when used as part of a <code>Project</code> run.</p>"},{"location":"cards/runcard/#creating-a-run","title":"Creating A Run","text":"<p>Runs are unqiue context-managed executions associated with a <code>Project</code> that record all created cards and their associated metrics, params, and artifacts to a single card called a <code>RunCard</code>.</p> <p>The following example shows how to create a simple run as well as use <code>CardInfo</code> to store helper info</p> <pre><code>import numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import Lasso\nfrom sklearn.metrics import mean_absolute_percentage_error\n\nfrom opsml.projects import OpsmlProject, ProjectInfo\nfrom opsml.registry import CardInfo, DataCard, ModelCard\n\ncard_info = CardInfo(name=\"linear-reg\", team=\"opsml\", user_email=\"user@email.com\")\n\n# to use runs, you must create and use a project\nproject_info = ProjectInfo(name=\"opsml-dev\", team=\"opsml\", user_email=\"user@email.com\")\nproject = OpsmlProject(info=project_info)\n\n\ndef create_fake_data():\n    X_train = np.random.normal(-4, 2.0, size=(1000, 10))\n\n    col_names = []\n    for i in range(0, X_train.shape[1]):\n        col_names.append(f\"col_{i}\")\n\n    X = pd.DataFrame(X_train, columns=col_names)\n    y = np.random.randint(1, 10, size=(1000, 1))\n\n    return X, y\n\n\n# start the run\nwith project.run(run_name=\"optional_run_name\") as run:\n\n    X, y = create_fake_data()\n\n    # train model\n    lasso = Lasso(alpha=0.5)\n    lasso = lasso.fit(X.to_numpy(), y)\n\n    preds = lasso.predict(X.to_numpy())\n\n    mape = mean_absolute_percentage_error(y, preds)\n\n    # Create metrics / params\n    run.log_metric(key=\"mape\", value=mape)\n    run.log_parameter(key=\"alpha\", value=0.5)\n\n    data_card = DataCard(data=X, info=card_info)\n    run.register_card(card=data_card, version_type=\"major\")  # you can specify \"major\", \"minor\", \"patch\"\n\n    model_card = ModelCard(\n        trained_model=lasso,\n        sample_input_data=X,\n        datacard_uid=data_card.uid,\n        info=card_info,\n    )\n    run.register_card(card=model_card)\n\nprint(run.runcard.get_metric(\"mape\"))\n# &gt; Metric(name='mape', value=0.8489706297619047, step=None, timestamp=None)\n\nprint(run.runcard.get_parameter(\"alpha\"))\n# &gt; Param(name='alpha', value=0.5)\n</code></pre>"},{"location":"cards/runcard/#creating-a-run-with-mlflow","title":"Creating A Run with MlFlow","text":"<p>If an <code>Opsml</code> server has been setup to use <code>Mlflow</code>, you can also associate an <code>MlflowProject</code> with a <code>RunCard</code>. The process is the same as above</p> <pre><code>from sklearn.linear_model import LinearRegression\nimport numpy as np\n\nfrom opsml.projects import ProjectInfo\n\nfrom opsml.projects.mlflow import MlflowProject\n\nfrom opsml.registry.cards import CardInfo\nfrom opsml.registry import DataCard, ModelCard, CardRegistry\n\n\ndef fake_data():\n    X_train = np.random.normal(-4, 2.0, size=(1000, 10))\n\n    col_names = []\n    for i in range(0, X_train.shape[1]):\n        col_names.append(f\"col_{i}\")\n\n    X = pd.DataFrame(X_train, columns=col_names)\n    y = np.random.randint(1, 10, size=(1000, 1))\n    return X, y\n\n\ninfo = ProjectInfo(name=\"opsml\", team=\"devops\", user_email=\"test_email\",)\nproject = MlflowProject(info=info)\nwith project.run(run_name=\"mlflow-test\") as run:\n\n    X, y = fake_data()\n    reg = LinearRegression().fit(X.to_numpy(), y)\n\n    data_card = DataCard(\n        data=X,\n        name=\"pipeline-data\",\n        team=\"mlops\",\n        user_email=\"mlops.com\",\n    )\n    run.register_card(card=data_card)\n\n    model_card = ModelCard(\n        trained_model=reg,\n        sample_input_data=X[0:1],\n        name=\"linear_reg\",\n        team=\"mlops\",\n        user_email=\"mlops.com\",\n        datacard_uid=data_card.uid,\n    )\n    run.register_card(card=model_card)\n    for i in range(0, 100):\n        run.log_metric(\"test\", i)\n</code></pre> <p>You can now log into the <code>Opsml</code> server and see your recent run and associated metadata</p>"},{"location":"cards/runcard/#opsml.registry.RunCard","title":"<code>opsml.registry.RunCard</code>","text":"<p>         Bases: <code>ArtifactCard</code></p> <p>Create a RunCard from specified arguments. Apart from required args, an Experiment card must be associated with one of datacard_uid, modelcard_uids or pipelinecard_uid</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <p>Run name</p> required <code>team</code> <p>Team that this card is associated with</p> required <code>user_email</code> <p>Email to associate with card</p> required <code>datacard_uid</code> <p>Optional DataCard uid associated with pipeline</p> required <code>modelcard_uids</code> <p>Optional List of ModelCard uids to associate with this run</p> required <code>pipelinecard_uid</code> <p>Optional PipelineCard uid to associate with this experiment</p> required <code>metrics</code> <p>Optional dictionary of key (str), value (int, float) metric paris. Metrics can also be added via class methods.</p> required <code>artifacts</code> <p>Optional dictionary of artifacts (i.e. plots, reports) to associate with the current run.</p> required <code>artifact_uris</code> <p>Optional dictionary of artifact uris associated with artifacts.</p> required <code>uid</code> <p>Unique id (assigned if card has been registered)</p> required <code>version</code> <p>Current version (assigned if card has been registered)</p> required Source code in <code>/home/steven_forrester/github/opsml-artifacts/opsml/registry/cards/cards.py</code> <pre><code>class RunCard(ArtifactCard):\n\n\"\"\"\n    Create a RunCard from specified arguments.\n    Apart from required args, an Experiment card must be associated with one of datacard_uid,\n    modelcard_uids or pipelinecard_uid\n\n    Args:\n        name:\n            Run name\n        team:\n            Team that this card is associated with\n        user_email:\n            Email to associate with card\n        datacard_uid:\n            Optional DataCard uid associated with pipeline\n        modelcard_uids:\n            Optional List of ModelCard uids to associate with this run\n        pipelinecard_uid:\n            Optional PipelineCard uid to associate with this experiment\n        metrics:\n            Optional dictionary of key (str), value (int, float) metric paris.\n            Metrics can also be added via class methods.\n        artifacts:\n            Optional dictionary of artifacts (i.e. plots, reports) to associate with\n            the current run.\n        artifact_uris:\n            Optional dictionary of artifact uris associated with artifacts.\n        uid:\n            Unique id (assigned if card has been registered)\n        version:\n            Current version (assigned if card has been registered)\n\n    \"\"\"\n\n    datacard_uids: List[str] = []\n    modelcard_uids: List[str] = []\n    pipelinecard_uid: Optional[str]\n    metrics: METRICS = {}\n    params: PARAMS = {}\n    artifacts: Dict[str, Any] = {}\n    artifact_uris: Dict[str, str] = {}\n    tags: Dict[str, str] = {}\n    project_id: Optional[str]\n    runcard_uri: Optional[str]\n\n    def add_tag(self, key: str, value: str):\n\"\"\"\n        Logs params to current RunCard\n\n        Args:\n            key:\n                Key for tag\n            value:\n                value for tag\n        \"\"\"\n        self.tags = {**{key: value}, **self.tags}\n\n    def add_tags(self, tags: Dict[str, str]):\n\"\"\"\n        Logs params to current RunCard\n\n        Args:\n            tags:\n                Dictionary of tags\n        \"\"\"\n        self.tags = {**tags, **self.tags}\n\n    def log_parameters(self, params: Dict[str, Union[float, int, str]]):\n\"\"\"\n        Logs params to current RunCard\n\n        Args:\n            params:\n                Dictionary of parameters\n        \"\"\"\n\n        for key, value in params.items():\n            # check key\n            self.log_parameter(key, value)\n\n    def log_parameter(self, key: str, value: Union[int, float, str]):\n\"\"\"\n        Logs params to current RunCard\n\n        Args:\n            key:\n                Param name\n            value:\n                Param value\n        \"\"\"\n\n        TypeChecker.check_param_type(param=value)\n        param = Param(name=key, value=value)\n\n        if self.params.get(key) is not None:\n            self.params[key].append(param)\n\n        else:\n            self.params[key] = [param]\n\n    def log_metric(\n        self,\n        key: str,\n        value: Union[int, float],\n        timestamp: Optional[int] = None,\n        step: Optional[int] = None,\n    ) -&gt; None:\n\"\"\"\n        Logs metric to the existing RunCard metric dictionary\n\n        Args:\n            key:\n                Metric name\n            value:\n                Metric value\n            timestamp:\n                Optional timestamp\n            ste:\n                Optional step associated with name and value\n        \"\"\"\n\n        TypeChecker.check_metric_type(metric=value)\n        metric = Metric(name=key, value=value, timestamp=timestamp, step=step)\n\n        if self.metrics.get(key) is not None:\n            self.metrics[key].append(metric)\n        else:\n            self.metrics[key] = [metric]\n\n    def log_metrics(self, metrics: Dict[str, Union[float, int]]) -&gt; None:\n\"\"\"\n        Log metrics to the existing RunCard metric dictionary\n\n        Args:\n            metrics:\n                Dictionary containing key (str) and value (float or int) pairs\n                to add to the current metric set\n        \"\"\"\n\n        for key, value in metrics.items():\n            self.log_metric(key, value)\n\n    def log_artifact(self, name: str, artifact: Any) -&gt; None:\n\"\"\"\n        Append any artifact associated with your run to\n        the RunCard. The aritfact will be saved and the uri\n        will be appended to the RunCard. Artifact must be pickleable\n        (saved with joblib)\n\n        Args:\n            name:\n                Artifact name\n            artifact:\n                Artifact\n        \"\"\"\n\n        curr_artifacts = cast(Dict[str, Any], self.artifacts)\n        new_artifact = {name: artifact}\n        self.artifacts = {**new_artifact, **curr_artifacts}\n        setattr(self, \"artifacts\", {**new_artifact, **self.artifacts})\n\n    def create_registry_record(self) -&gt; RegistryRecord:\n\"\"\"Creates a registry record from the current RunCard\"\"\"\n\n        exclude_attr = {\"artifacts\", \"storage_client\", \"params\", \"metrics\"}\n\n        return RunRegistryRecord(**self.dict(exclude=exclude_attr))\n\n    def add_artifact_uri(self, name: str, uri: str):\n\"\"\"\n        Adds an artifact_uri to the runcard\n\n        Args:\n            name:\n                Name to associate with artifact\n            uri:\n                Uri where artifact is stored\n        \"\"\"\n\n        self.artifact_uris[name] = uri\n\n    def add_card_uid(self, card_type: str, uid: str) -&gt; None:\n\"\"\"\n        Adds a card uid to the appropriact card uid list for tracking\n\n        Args:\n            card_type:\n                ArtifactCard class name\n            uid:\n                Uid of registered ArtifactCard\n        \"\"\"\n\n        if card_type == CardType.DATACARD:\n            self.datacard_uids = [uid, *self.datacard_uids]\n        elif card_type == CardType.MODELCARD:\n            self.modelcard_uids = [uid, *self.modelcard_uids]\n\n    def get_metric(self, name: str) -&gt; Union[List[Metric], Metric]:\n\"\"\"\n        Gets a metric by name\n\n        Args:\n            name:\n                Name of metric\n\n        Returns:\n            List of dictionaries or dictionary containing value\n\n        \"\"\"\n        metric = self.metrics.get(name)\n        if metric is not None:\n            if len(metric) &gt; 1:\n                return metric\n            if len(metric) == 1:\n                return metric[0]\n            return metric\n\n        raise ValueError(f\"Metric {metric} is not defined\")\n\n    def get_parameter(self, name: str) -&gt; Union[List[Param], Param]:\n\"\"\"\n        Gets a metric by name\n\n        Args:\n            name:\n                Name of param\n\n        Returns:\n            List of dictionaries or dictionary containing value\n\n        \"\"\"\n        param = self.params.get(name)\n        if param is not None:\n            if len(param) &gt; 1:\n                return param\n            if len(param) == 1:\n                return param[0]\n            return param\n\n        raise ValueError(f\"Param {param} is not defined\")\n\n    def load_artifacts(self) -&gt; None:\n        if bool(self.artifact_uris) and self.storage_client is not None:\n            for name, uri in self.artifact_uris.items():\n                storage_spec = ArtifactStorageSpecs(save_path=uri)\n                self.storage_client.storage_spec = storage_spec\n                self.artifacts[name] = load_record_artifact_from_storage(\n                    storage_client=self.storage_client,\n                    artifact_type=ARBITRARY_ARTIFACT_TYPE,\n                )\n            return None\n\n        logger.info(\"No artifact uris associated with RunCard\")\n        return None\n\n    @property\n    def card_type(self) -&gt; str:\n        return CardType.RUNCARD.value\n</code></pre>"},{"location":"cards/runcard/#opsml.registry.cards.cards.RunCard.add_tag","title":"<code>add_tag(key, value)</code>","text":"<p>Logs params to current RunCard</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Key for tag</p> required <code>value</code> <code>str</code> <p>value for tag</p> required Source code in <code>/home/steven_forrester/github/opsml-artifacts/opsml/registry/cards/cards.py</code> <pre><code>def add_tag(self, key: str, value: str):\n\"\"\"\n    Logs params to current RunCard\n\n    Args:\n        key:\n            Key for tag\n        value:\n            value for tag\n    \"\"\"\n    self.tags = {**{key: value}, **self.tags}\n</code></pre>"},{"location":"cards/runcard/#opsml.registry.cards.cards.RunCard.log_parameter","title":"<code>log_parameter(key, value)</code>","text":"<p>Logs params to current RunCard</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Param name</p> required <code>value</code> <code>Union[int, float, str]</code> <p>Param value</p> required Source code in <code>/home/steven_forrester/github/opsml-artifacts/opsml/registry/cards/cards.py</code> <pre><code>def log_parameter(self, key: str, value: Union[int, float, str]):\n\"\"\"\n    Logs params to current RunCard\n\n    Args:\n        key:\n            Param name\n        value:\n            Param value\n    \"\"\"\n\n    TypeChecker.check_param_type(param=value)\n    param = Param(name=key, value=value)\n\n    if self.params.get(key) is not None:\n        self.params[key].append(param)\n\n    else:\n        self.params[key] = [param]\n</code></pre>"},{"location":"cards/runcard/#opsml.registry.cards.cards.RunCard.log_parameters","title":"<code>log_parameters(params)</code>","text":"<p>Logs params to current RunCard</p> <p>Parameters:</p> Name Type Description Default <code>params</code> <code>Dict[str, Union[float, int, str]]</code> <p>Dictionary of parameters</p> required Source code in <code>/home/steven_forrester/github/opsml-artifacts/opsml/registry/cards/cards.py</code> <pre><code>def log_parameters(self, params: Dict[str, Union[float, int, str]]):\n\"\"\"\n    Logs params to current RunCard\n\n    Args:\n        params:\n            Dictionary of parameters\n    \"\"\"\n\n    for key, value in params.items():\n        # check key\n        self.log_parameter(key, value)\n</code></pre>"},{"location":"cards/runcard/#opsml.registry.cards.cards.RunCard.log_metric","title":"<code>log_metric(key, value, timestamp=None, step=None)</code>","text":"<p>Logs metric to the existing RunCard metric dictionary</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Metric name</p> required <code>value</code> <code>Union[int, float]</code> <p>Metric value</p> required <code>timestamp</code> <code>Optional[int]</code> <p>Optional timestamp</p> <code>None</code> <code>ste</code> <p>Optional step associated with name and value</p> required Source code in <code>/home/steven_forrester/github/opsml-artifacts/opsml/registry/cards/cards.py</code> <pre><code>def log_metric(\n    self,\n    key: str,\n    value: Union[int, float],\n    timestamp: Optional[int] = None,\n    step: Optional[int] = None,\n) -&gt; None:\n\"\"\"\n    Logs metric to the existing RunCard metric dictionary\n\n    Args:\n        key:\n            Metric name\n        value:\n            Metric value\n        timestamp:\n            Optional timestamp\n        ste:\n            Optional step associated with name and value\n    \"\"\"\n\n    TypeChecker.check_metric_type(metric=value)\n    metric = Metric(name=key, value=value, timestamp=timestamp, step=step)\n\n    if self.metrics.get(key) is not None:\n        self.metrics[key].append(metric)\n    else:\n        self.metrics[key] = [metric]\n</code></pre>"},{"location":"cards/runcard/#opsml.registry.cards.cards.RunCard.log_metrics","title":"<code>log_metrics(metrics)</code>","text":"<p>Log metrics to the existing RunCard metric dictionary</p> <p>Parameters:</p> Name Type Description Default <code>metrics</code> <code>Dict[str, Union[float, int]]</code> <p>Dictionary containing key (str) and value (float or int) pairs to add to the current metric set</p> required Source code in <code>/home/steven_forrester/github/opsml-artifacts/opsml/registry/cards/cards.py</code> <pre><code>def log_metrics(self, metrics: Dict[str, Union[float, int]]) -&gt; None:\n\"\"\"\n    Log metrics to the existing RunCard metric dictionary\n\n    Args:\n        metrics:\n            Dictionary containing key (str) and value (float or int) pairs\n            to add to the current metric set\n    \"\"\"\n\n    for key, value in metrics.items():\n        self.log_metric(key, value)\n</code></pre>"},{"location":"cards/runcard/#opsml.registry.cards.cards.RunCard.log_artifact","title":"<code>log_artifact(name, artifact)</code>","text":"<p>Append any artifact associated with your run to the RunCard. The aritfact will be saved and the uri will be appended to the RunCard. Artifact must be pickleable (saved with joblib)</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Artifact name</p> required <code>artifact</code> <code>Any</code> <p>Artifact</p> required Source code in <code>/home/steven_forrester/github/opsml-artifacts/opsml/registry/cards/cards.py</code> <pre><code>def log_artifact(self, name: str, artifact: Any) -&gt; None:\n\"\"\"\n    Append any artifact associated with your run to\n    the RunCard. The aritfact will be saved and the uri\n    will be appended to the RunCard. Artifact must be pickleable\n    (saved with joblib)\n\n    Args:\n        name:\n            Artifact name\n        artifact:\n            Artifact\n    \"\"\"\n\n    curr_artifacts = cast(Dict[str, Any], self.artifacts)\n    new_artifact = {name: artifact}\n    self.artifacts = {**new_artifact, **curr_artifacts}\n    setattr(self, \"artifacts\", {**new_artifact, **self.artifacts})\n</code></pre>"},{"location":"cards/runcard/#opsml.projects.mlflow.project.MlflowProject","title":"<code>opsml.projects.mlflow.project.MlflowProject</code>","text":"<p>         Bases: <code>OpsmlProject</code></p> Source code in <code>/home/steven_forrester/github/opsml-artifacts/opsml/projects/mlflow/project.py</code> <pre><code>class MlflowProject(OpsmlProject):\n    def __init__(self, info: ProjectInfo):  # pylint: disable=super-init-not-called\n\"\"\"\n        Instantiates an mlflow project which log cards, metrics and params to\n        the opsml registry and mlflow via a \"run\" object.\n\n        If info.run_id is set, that run_id will be loaded as read only. In read\n        only mode, you can retrieve cards, metrics, and params, however you\n        cannot write new data. If you wish to record data/create a new run, you will\n        need to enter the run context.\n\n        Example:\n\n            ```python\n            project: MlFlowProject = get_project(\n                ProjectInfo(\n                    name=\"test-project\",\n                    team=\"devops-ml\",\n                    # If run_id is omitted, a new run is created.\n                    run_id=\"123ab123kaj8u8naskdfh813\",\n                )\n            )\n            # the project is in \"read only\" mode. all read operations will work\n            for k, v in project.params:\n                logger.info(\"%s = %s\", k, v)\n\n            # creating a project run\n            with project.run() as run:\n                # Now that the run context is entered, it's in read/write mode\n                # You can write cards, params, and metrics to the project.\n                run.log_parameter(key=\"my_param\", value=\"12.34\")\n            ```\n\n        Args:\n            info:\n                Run information. if a run_id is given, that run is set\n                as the project's current run.\n        \"\"\"\n\n        # Set RunManager\n        self._run_mgr = _MlflowRunManager(project_info=info)\n\n    @property\n    def run_data(self) -&gt; RunData:\n\"\"\"Returns all `RunData` associated with a Run\"\"\"\n        return self._run_mgr.mlflow_client.get_run(self.run_id).data  # type: ignore\n\n    @contextmanager\n    def run(self, run_name: Optional[str] = None) -&gt; Iterator[MlflowActiveRun]:\n\"\"\"\n        Starts mlflow run for project\n\n        Args:\n            run_name:\n                Optional run name\n        \"\"\"\n\n        self._run_mgr.start_run(run_name=run_name)\n\n        yield cast(MlflowActiveRun, self._run_mgr.active_run)\n\n        self._run_mgr.end_run()\n\n    def download_artifacts(\n        self,\n        artifact_path: Optional[str] = None,\n        local_path: Optional[str] = None,\n    ) -&gt; str:\n\"\"\"\n        Download an artifact or artifacts associated with a run_id\n\n        Args:\n            artifact_path:\n                Optional path that contains artifact(s) to download\n            local_path:\n                Local path (directory) to download artifacts to\n\n        Returns:\n            Artifact path\n        \"\"\"\n        return download_artifacts(\n            run_id=self.run_id,\n            artifact_path=artifact_path,\n            dst_path=local_path,\n            tracking_uri=self._run_mgr.mlflow_client.tracking_uri,  # type: ignore\n        )\n\n    def list_artifacts(self, path: Optional[str] = None) -&gt; dict[str, float]:\n\"\"\"List artifacts for the current run\"\"\"\n        return self._run_mgr.mlflow_client.list_artifacts(  # type: ignore\n            run_id=self.run_id,\n            path=path,\n        )\n\n    @property\n    def metrics(self) -&gt; METRICS:\n\"\"\"Returns a Run's metrics\n\n        Example:\n            ```python\n            info = ProjectInfo(name=\"opsml\", team=\"devops\",user_email=\"test_email\",run_id=run.run_id)\n            project = MlflowProject(info=info)\n            project.metrics\n\n            {\n                'test': [Metric(name='test', value=99.0, step=None, timestamp=None)],\n                'r2': [Metric(name='r2', value=0.006525740117159562, step=None, timestamp=None)],\n                'mae': [Metric(name='mae', value=2.225978693518221, step=None, timestamp=None)]\n            }\n\n            ```\n        \"\"\"\n\n        metrics: METRICS = {}\n        for key, value in self.run_data.metrics.items():\n            metrics[key] = [Metric(name=key, value=value)]  # keep consistency with RunCard type\n        return metrics\n\n    def get_metric(self, name: str) -&gt; Union[List[Metric], Metric]:\n\"\"\"\n        Get metric by name\n\n        Args:\n            name: str\n\n        Returns:\n            `Metric`\n\n        \"\"\"\n        metric = self.metrics.get(name)\n\n        if metric is not None:\n            return metric[0]\n\n        raise ValueError(f\"Metric {name} not found\")\n\n    @property\n    def params(self) -&gt; PARAMS:\n\"\"\"Returns a Run's parameters\"\"\"\n        params: PARAMS = {}\n        for key, value in self.run_data.params.items():\n            params[key] = [Param(name=key, value=value)]\n        return params\n\n    def get_parameter(self, name: str) -&gt; Union[List[Param], Param]:\n\"\"\"\n        Get param by name\n\n        Args:\n            name: str\n\n        Returns:\n            `Param`\n\n        \"\"\"\n        param = self.params.get(name)\n        if param is not None:\n            return param[0]\n\n        raise ValueError(f\"Param {name} not found\")\n\n    @property\n    def tags(self) -&gt; dict[str, str]:\n\"\"\"Returns a Run's tags\"\"\"\n        return self.run_data.tags\n</code></pre>"},{"location":"cards/runcard/#opsml.projects.mlflow.project.MlflowProject.metrics","title":"<code>metrics: METRICS</code>  <code>property</code>","text":"<p>Returns a Run's metrics</p> Example <pre><code>info = ProjectInfo(name=\"opsml\", team=\"devops\",user_email=\"test_email\",run_id=run.run_id)\nproject = MlflowProject(info=info)\nproject.metrics\n\n{\n    'test': [Metric(name='test', value=99.0, step=None, timestamp=None)],\n    'r2': [Metric(name='r2', value=0.006525740117159562, step=None, timestamp=None)],\n    'mae': [Metric(name='mae', value=2.225978693518221, step=None, timestamp=None)]\n}\n</code></pre>"},{"location":"cards/runcard/#opsml.projects.mlflow.project.MlflowProject.params","title":"<code>params: PARAMS</code>  <code>property</code>","text":"<p>Returns a Run's parameters</p>"},{"location":"cards/runcard/#opsml.projects.mlflow.project.MlflowProject.run_data","title":"<code>run_data: RunData</code>  <code>property</code>","text":"<p>Returns all <code>RunData</code> associated with a Run</p>"},{"location":"cards/runcard/#opsml.projects.mlflow.project.MlflowProject.tags","title":"<code>tags: dict[str, str]</code>  <code>property</code>","text":"<p>Returns a Run's tags</p>"},{"location":"cards/runcard/#opsml.projects.mlflow.project.MlflowProject.__init__","title":"<code>__init__(info)</code>","text":"<p>Instantiates an mlflow project which log cards, metrics and params to the opsml registry and mlflow via a \"run\" object.</p> <p>If info.run_id is set, that run_id will be loaded as read only. In read only mode, you can retrieve cards, metrics, and params, however you cannot write new data. If you wish to record data/create a new run, you will need to enter the run context.</p> Example <pre><code>project: MlFlowProject = get_project(\n    ProjectInfo(\n        name=\"test-project\",\n        team=\"devops-ml\",\n        # If run_id is omitted, a new run is created.\n        run_id=\"123ab123kaj8u8naskdfh813\",\n    )\n)\n# the project is in \"read only\" mode. all read operations will work\nfor k, v in project.params:\n    logger.info(\"%s = %s\", k, v)\n\n# creating a project run\nwith project.run() as run:\n    # Now that the run context is entered, it's in read/write mode\n    # You can write cards, params, and metrics to the project.\n    run.log_parameter(key=\"my_param\", value=\"12.34\")\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>info</code> <code>ProjectInfo</code> <p>Run information. if a run_id is given, that run is set as the project's current run.</p> required Source code in <code>/home/steven_forrester/github/opsml-artifacts/opsml/projects/mlflow/project.py</code> <pre><code>def __init__(self, info: ProjectInfo):  # pylint: disable=super-init-not-called\n\"\"\"\n    Instantiates an mlflow project which log cards, metrics and params to\n    the opsml registry and mlflow via a \"run\" object.\n\n    If info.run_id is set, that run_id will be loaded as read only. In read\n    only mode, you can retrieve cards, metrics, and params, however you\n    cannot write new data. If you wish to record data/create a new run, you will\n    need to enter the run context.\n\n    Example:\n\n        ```python\n        project: MlFlowProject = get_project(\n            ProjectInfo(\n                name=\"test-project\",\n                team=\"devops-ml\",\n                # If run_id is omitted, a new run is created.\n                run_id=\"123ab123kaj8u8naskdfh813\",\n            )\n        )\n        # the project is in \"read only\" mode. all read operations will work\n        for k, v in project.params:\n            logger.info(\"%s = %s\", k, v)\n\n        # creating a project run\n        with project.run() as run:\n            # Now that the run context is entered, it's in read/write mode\n            # You can write cards, params, and metrics to the project.\n            run.log_parameter(key=\"my_param\", value=\"12.34\")\n        ```\n\n    Args:\n        info:\n            Run information. if a run_id is given, that run is set\n            as the project's current run.\n    \"\"\"\n\n    # Set RunManager\n    self._run_mgr = _MlflowRunManager(project_info=info)\n</code></pre>"},{"location":"cards/runcard/#opsml.projects.mlflow.project.MlflowProject.download_artifacts","title":"<code>download_artifacts(artifact_path=None, local_path=None)</code>","text":"<p>Download an artifact or artifacts associated with a run_id</p> <p>Parameters:</p> Name Type Description Default <code>artifact_path</code> <code>Optional[str]</code> <p>Optional path that contains artifact(s) to download</p> <code>None</code> <code>local_path</code> <code>Optional[str]</code> <p>Local path (directory) to download artifacts to</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>Artifact path</p> Source code in <code>/home/steven_forrester/github/opsml-artifacts/opsml/projects/mlflow/project.py</code> <pre><code>def download_artifacts(\n    self,\n    artifact_path: Optional[str] = None,\n    local_path: Optional[str] = None,\n) -&gt; str:\n\"\"\"\n    Download an artifact or artifacts associated with a run_id\n\n    Args:\n        artifact_path:\n            Optional path that contains artifact(s) to download\n        local_path:\n            Local path (directory) to download artifacts to\n\n    Returns:\n        Artifact path\n    \"\"\"\n    return download_artifacts(\n        run_id=self.run_id,\n        artifact_path=artifact_path,\n        dst_path=local_path,\n        tracking_uri=self._run_mgr.mlflow_client.tracking_uri,  # type: ignore\n    )\n</code></pre>"},{"location":"cards/runcard/#opsml.projects.mlflow.project.MlflowProject.get_metric","title":"<code>get_metric(name)</code>","text":"<p>Get metric by name</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>str</p> required <p>Returns:</p> Type Description <code>Union[List[Metric], Metric]</code> <p><code>Metric</code></p> Source code in <code>/home/steven_forrester/github/opsml-artifacts/opsml/projects/mlflow/project.py</code> <pre><code>def get_metric(self, name: str) -&gt; Union[List[Metric], Metric]:\n\"\"\"\n    Get metric by name\n\n    Args:\n        name: str\n\n    Returns:\n        `Metric`\n\n    \"\"\"\n    metric = self.metrics.get(name)\n\n    if metric is not None:\n        return metric[0]\n\n    raise ValueError(f\"Metric {name} not found\")\n</code></pre>"},{"location":"cards/runcard/#opsml.projects.mlflow.project.MlflowProject.get_parameter","title":"<code>get_parameter(name)</code>","text":"<p>Get param by name</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>str</p> required <p>Returns:</p> Type Description <code>Union[List[Param], Param]</code> <p><code>Param</code></p> Source code in <code>/home/steven_forrester/github/opsml-artifacts/opsml/projects/mlflow/project.py</code> <pre><code>def get_parameter(self, name: str) -&gt; Union[List[Param], Param]:\n\"\"\"\n    Get param by name\n\n    Args:\n        name: str\n\n    Returns:\n        `Param`\n\n    \"\"\"\n    param = self.params.get(name)\n    if param is not None:\n        return param[0]\n\n    raise ValueError(f\"Param {name} not found\")\n</code></pre>"},{"location":"cards/runcard/#opsml.projects.mlflow.project.MlflowProject.list_artifacts","title":"<code>list_artifacts(path=None)</code>","text":"<p>List artifacts for the current run</p> Source code in <code>/home/steven_forrester/github/opsml-artifacts/opsml/projects/mlflow/project.py</code> <pre><code>def list_artifacts(self, path: Optional[str] = None) -&gt; dict[str, float]:\n\"\"\"List artifacts for the current run\"\"\"\n    return self._run_mgr.mlflow_client.list_artifacts(  # type: ignore\n        run_id=self.run_id,\n        path=path,\n    )\n</code></pre>"},{"location":"cards/runcard/#opsml.projects.mlflow.project.MlflowProject.run","title":"<code>run(run_name=None)</code>","text":"<p>Starts mlflow run for project</p> <p>Parameters:</p> Name Type Description Default <code>run_name</code> <code>Optional[str]</code> <p>Optional run name</p> <code>None</code> Source code in <code>/home/steven_forrester/github/opsml-artifacts/opsml/projects/mlflow/project.py</code> <pre><code>@contextmanager\ndef run(self, run_name: Optional[str] = None) -&gt; Iterator[MlflowActiveRun]:\n\"\"\"\n    Starts mlflow run for project\n\n    Args:\n        run_name:\n            Optional run name\n    \"\"\"\n\n    self._run_mgr.start_run(run_name=run_name)\n\n    yield cast(MlflowActiveRun, self._run_mgr.active_run)\n\n    self._run_mgr.end_run()\n</code></pre>"},{"location":"server/example_toml/","title":"Example pyproject toml for <code>Opsml</code> Setup (with <code>Mlflow</code>)","text":"<pre><code>[tool.poetry]\nname = \"opsml-api\"\nversion = \"0.1.0\"\ndescription = \"\"\nauthors = [\"devops-ml\"]\n\n[tool.poetry.dependencies]\npython = \"&gt;=3.9,&lt;=3.11\"\nllvmlite = \"^0.39.1\"\nmlflow = \"^2.2.1\"\nnumba = \"^0.56.4\"\npyshipt-logging = \"^1.0.4\"\npsycopg2 = \"^2.9.5\"\nopsml = {version = \"0.3.3\", extras = [\"gcp-postgres\", \"server\"]}\ngcsfs = \"&gt;=2022.11.0,&lt;2023.0.0\"\ngoogle-auth = \"1.35.0\"\ngoogle-cloud-storage = \"&gt;=2.2.1,&lt;3.0.0\"\n</code></pre>"},{"location":"server/overview/","title":"<code>Opsml</code> Server Setup","text":"<p>In addition to using <code>Opsml</code> as a stand-alone python package, it can also be used as a server (<code>FastApi</code>) providing a proxy interface between data scientists and backend infrastructure. What this means for data scientists, is that they can use <code>Opsml</code> as they normally would without having to set any credentials apart from the http proxy uri. For engineers, this means that they can control the infrastucture, databases, and overall server setup based on their specifications and security requirements.</p> <p></p>"},{"location":"server/overview/#setup","title":"Setup","text":"<p>You can setup the <code>Opsml</code> server based on your team needs. For our purposes at <code>Shipt</code>, we tend to follow a conventional setup whereby we host Docker images via K8s. For this setup up, we typically will install <code>Opsml</code> and its dependencies into a Dockerfile and then at webserver runtime, we execute the following command:</p> <ul> <li> <p><code>gunicorn -k uvicorn.workers.UvicornWorker --config=./app/gunicorn_conf.py --bind=0.0.0.0:3000 \"opsml.app.main:run_app(run_mlflow=True, login=False)\"</code></p> </li> <li> <p>To use Mlflow with the <code>Opsml</code> server, you will also need to install the <code>Mlflow</code> extras (see example_pyproject)</p> </li> </ul>"}]}